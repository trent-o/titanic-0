{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(r\"C:\\Users\\trent\\github_repos\\titanic-0\\train.csv\")\n",
    "\n",
    "df_test = pd.read_csv(r\"C:\\Users\\trent\\github_repos\\titanic-0\\test.csv\")\n",
    "\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_dummies(X, categoricalNumericFeatures=[]):\n",
    "    # Note the parameter is X, which does not include the label\n",
    "    for col in X:\n",
    "        if not pd.api.types.is_numeric_dtype(X[col]) or categoricalNumericFeatures.count(col) > 0:\n",
    "            X = pd.get_dummies(X, columns=[col], prefix=col, drop_first=True,dummy_na=True)\n",
    "    return X\n",
    "\n",
    "def bin_groups(df, categoricalNumericFeatures=[], percent=.05):\n",
    "    import pandas as pd\n",
    "\n",
    "    for col in df:\n",
    "        # if the column is categorical\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]) or categoricalNumericFeatures.count(col) > 0:\n",
    "            for group, count in df[col].value_counts().iteritems():\n",
    "                # For each categorical value, if the percentage of the column that contains that value is below the threshold, relabel to other\n",
    "                if count / len(df) < percent:\n",
    "                    df.loc[df[col] == group, col] = 'Other'\n",
    "    return df\n",
    "\n",
    "def drop_cols_too_unique(df, percent = .80):\n",
    "\n",
    "    for col in df:\n",
    "        pct = len(df[df[col] == 'Other'][col]) / len(df)\n",
    "        if pct >=.80:\n",
    "            df.drop(columns=col, inplace=True)\n",
    "            print(\"dropped \" + col + \", \" + str(pct * 100) + \"% unique\")\n",
    "    return df        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MissingData:\n",
    "\n",
    "    def __init__(self, df, categoricalImputer='', numericalImputer='', categoricalNumericFeatures=[], dropColPct = .5):\n",
    "        self.categoricalImputer = categoricalImputer\n",
    "        self.numericalImputer = numericalImputer\n",
    "        self.df = df\n",
    "        self.categoricalNumericFeatures = categoricalNumericFeatures\n",
    "        self.dropColPct = dropColPct\n",
    "\n",
    "    def fillMissingData(self):\n",
    "        # get number of categorical and numeric columns missing data\n",
    "        nCat, nNum = self.missing_values_check(self.df,self.categoricalNumericFeatures)\n",
    "\n",
    "        # if no columns are missing data, we are done\n",
    "        if nCat + nNum == 0:\n",
    "            print(\"Missing data check complete. No columns have missing data.\")\n",
    "            return\n",
    "        \n",
    "        # drop columns missing too much data\n",
    "        self.df = self.drop_cols_missing_data(self.df,self.dropColPct)\n",
    "\n",
    "        # handle categorical columns missing data\n",
    "        if nCat != 0:\n",
    "            if self.categoricalImputer == 'most_frequent':\n",
    "                imp = self.impute_mode()\n",
    "            else:\n",
    "                raise ValueError(\"Invalid categorical imputer.\")\n",
    "        \n",
    "            self.df = self.selective_sklearn_impute(self.df, imp,'categorical',self.categoricalNumericFeatures)\n",
    "            print(f\"imputed {nCat} categorical column(s) using {self.categoricalImputer}.\")\n",
    "        \n",
    "        # handle numeric columns missing data\n",
    "        if nNum != 0: \n",
    "            if self.numericalImputer == 'mean':\n",
    "                imp = self.impute_mean()\n",
    "            elif self.numericalImputer == 'knn':\n",
    "                imp = self.impute_KNN()\n",
    "            elif self.numericalImputer == 'reg':\n",
    "                imp = self.impute_reg()\n",
    "            else: \n",
    "                raise ValueError(\"Invalid numeric imputer.\")\n",
    "            \n",
    "            self.df = self.selective_sklearn_impute(self.df,imp,'numeric',self.categoricalNumericFeatures)\n",
    "            print(f\"imputed {nNum} numeric column(s) using {self.numericalImputer}.\")\n",
    "\n",
    "        # Check that filling in the missing data worked\n",
    "        # get number of categorical and numeric columns missing data\n",
    "        nCat, nNum = self.missing_values_check(self.df,self.categoricalNumericFeatures)\n",
    "\n",
    "        # if no columns are missing data, we are done\n",
    "        if nCat + nNum == 0:\n",
    "            print(\"Missing data check complete. No columns have missing data.\")\n",
    "        else:\n",
    "            raise ValueError(\"Missing data check failed. Some columns have missing data.\")\n",
    "        return self.df\n",
    "\n",
    "    def missing_values_report(self):\n",
    "        df = self.df\n",
    "\n",
    "        for col in df:\n",
    "            print(f'{col}\\t{round(df[col].isnull().sum() / len(df) * 100,2)}%')\n",
    "\n",
    "    def missing_values_check(self, df, categoricalNumericFeatures):\n",
    "        catColsMissingData = 0\n",
    "        numColsMissingData = 0\n",
    "\n",
    "        for col in df:\n",
    "            #if there is at least one null value in the column\n",
    "            if df[col].isnull().sum() > 0:\n",
    "\n",
    "                #if its a categorical column\n",
    "                if not pd.api.types.is_numeric_dtype(df[col]) or col in categoricalNumericFeatures:\n",
    "                    catColsMissingData += 1\n",
    "                else:\n",
    "                    numColsMissingData +=1\n",
    "        \n",
    "        return catColsMissingData, numColsMissingData\n",
    "\n",
    "    def drop_cols_missing_data(self, df, percent=.5):\n",
    "        for col in df:\n",
    "            if df[col].isna().sum()/len(df) > percent:\n",
    "                df = df.drop(columns=col)\n",
    "                print(\"dropped the \" + col + \" column. Over \" + str(round(percent*100)) + \"% of records were Null.\" )\n",
    "        return df\n",
    "\n",
    "    # IMPUTATION \n",
    "    def selective_sklearn_impute(self, df, imp, type, categoricalNumericFeatures = []):\n",
    "        validTypes = ['categorical', 'numeric']\n",
    "        if type not in validTypes:\n",
    "            raise ValueError(\"Invalid type. Expected one of: %s\" % validTypes)\n",
    "        \n",
    "        if type == 'categorical':\n",
    "            # Only impute on categorical columns\n",
    "            dfCategorical = df.select_dtypes(include='object')\n",
    "            # if there are categorical features that are numerical, include them (ex: 1, 0 for survived)\n",
    "            if len(categoricalNumericFeatures) != 0:\n",
    "                for colName in categoricalNumericFeatures:\n",
    "                    dfCategorical = dfCategorical.join(df[colName])\n",
    "            dfCategorical = pd.DataFrame(imp.fit_transform(dfCategorical), columns=dfCategorical.columns)\n",
    "\n",
    "            # Replace the old categorical columns with the new imputed ones.\n",
    "            df.drop(columns=dfCategorical.columns, inplace=True)\n",
    "            df = df.join(dfCategorical)\n",
    "\n",
    "        elif type == 'numeric':\n",
    "            # Only impute on numeric columns\n",
    "            dfNumeric = df.select_dtypes(include='number')\n",
    "            # if there are categorical features that are numerical, don't include them (ex: 1, 0 for survived)\n",
    "            if len(categoricalNumericFeatures) != 0:\n",
    "                for colName in categoricalNumericFeatures:\n",
    "                    if colName in dfNumeric.columns:\n",
    "                        dfNumeric = dfNumeric.drop(columns=colName)\n",
    "            dfNumeric = pd.DataFrame(imp.fit_transform(dfNumeric), columns=dfNumeric.columns)\n",
    "\n",
    "            # Replace the old numeric columns with the new imputed ones.\n",
    "            df.drop(columns=dfNumeric.columns, inplace=True)\n",
    "            df = df.join(dfNumeric)\n",
    "        return df\n",
    "\n",
    "    ## CATEGORICAL IMPUTATION\n",
    "    def impute_mode(self):\n",
    "        from sklearn.impute import SimpleImputer\n",
    "\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "        return imp\n",
    "\n",
    "    ## NUMERICAL IMPUTATION\n",
    "    def impute_mean(self):\n",
    "        from sklearn.impute import SimpleImputer\n",
    "\n",
    "        # Change the strategy to mean, median, or mode\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "        return imp\n",
    "\n",
    "    def impute_KNN(self):\n",
    "        from sklearn.impute import KNNImputer\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "        # Clustering is biased by unstandardized data; so MinMax scale it\n",
    "        #df = pd.DataFrame(MinMaxScaler().fit_transform(df), columns = df.columns)\n",
    "\n",
    "        print(\"did you standardize the data before impute KNN?\")\n",
    "        imp = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "        return imp\n",
    "\n",
    "    def impute_reg(self):\n",
    "        from sklearn.experimental import enable_iterative_imputer\n",
    "        from sklearn.impute import IterativeImputer\n",
    "\n",
    "        # Scaling is unnecessary for regression-based imputation\n",
    "        imp = IterativeImputer(max_iter=10, random_state=12345)\n",
    "        return imp\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId\t0.0%\n",
      "Survived\t0.0%\n",
      "Pclass\t0.0%\n",
      "Name\t0.0%\n",
      "Sex\t0.0%\n",
      "Age\t19.87%\n",
      "SibSp\t0.0%\n",
      "Parch\t0.0%\n",
      "Ticket\t0.0%\n",
      "Fare\t0.0%\n",
      "Cabin\t77.1%\n",
      "Embarked\t0.22%\n"
     ]
    }
   ],
   "source": [
    "# Drop columns missing a lot of data (80%).\n",
    "df = df_train.copy()\n",
    "\n",
    "missingData = MissingData(df, 'most_frequent','mean', ['Pclass'], .8)\n",
    "missingData.missing_values_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin and Embarked are categorical columns, and right now I will only be using mode imputation for categorical columns. Since imputing mode on cabin will likely not yield any great results, I will drop cabin and continue with imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputed 1 categorical column(s) using most_frequent.\n",
      "imputed 1 numeric column(s) using mean.\n",
      "Missing data check complete. No columns have missing data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>113803</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>373450</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name     Sex  \\\n",
       "0                            Braund, Mr. Owen Harris    male   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
       "2                             Heikkinen, Miss. Laina  female   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
       "4                           Allen, Mr. William Henry    male   \n",
       "\n",
       "             Ticket Embarked Pclass  PassengerId  Survived   Age  SibSp  \\\n",
       "0         A/5 21171        S      3          1.0       0.0  22.0    1.0   \n",
       "1          PC 17599        C      1          2.0       1.0  38.0    1.0   \n",
       "2  STON/O2. 3101282        S      3          3.0       1.0  26.0    0.0   \n",
       "3            113803        S      1          4.0       1.0  35.0    1.0   \n",
       "4            373450        S      3          5.0       0.0  35.0    0.0   \n",
       "\n",
       "   Parch     Fare  \n",
       "0    0.0   7.2500  \n",
       "1    0.0  71.2833  \n",
       "2    0.0   7.9250  \n",
       "3    0.0  53.1000  \n",
       "4    0.0   8.0500  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns='Cabin', inplace=True)\n",
    "df = missingData.fillMissingData()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (mlr): \t0.3647396296033043\n",
      "R-squared scores: \n",
      "[0.36473963 0.3114511  0.44027592 0.43424407 0.36937612 0.32367679\n",
      " 0.40639937 0.33919578 0.38460849 0.46091504 0.38435369 0.44095512\n",
      " 0.44551067 0.32924852 0.31186896 0.44691472 0.43244886 0.31745425\n",
      " 0.40926906 0.28456117 0.40967504 0.33793145 0.30977401 0.44706372\n",
      " 0.36486114]\n",
      "\n",
      "Average R-squared:\t0.3802709079694058\n"
     ]
    }
   ],
   "source": [
    "def fit_mlr(df, test_size=.2, random_state=12345, label=''):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X = df.drop(label,axis=1)\n",
    "    y = df[label]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    print(f'R-squared (mlr): \\t{model.score(X_test, y_test)}')\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_crossvalidate_mlr(df, k, label, repeat=True):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score\n",
    "    from numpy import mean, std\n",
    "\n",
    "    X = df.drop(label,axis=1)\n",
    "    y = df[label]\n",
    "\n",
    "    # prepare the cross-validation procedure\n",
    "    if repeat:\n",
    "        cv = RepeatedKFold(n_splits=k, n_repeats=5, random_state=12345)\n",
    "    else:\n",
    "        cv = KFold(n_splits=k, random_state=12345, shuffle=True)\n",
    "    \n",
    "\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(LinearRegression(), X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "\n",
    "    # report performance\n",
    "    print(f'R-squared scores: \\n{scores}\\n')\n",
    "    print(f'Average R-squared:\\t{mean(scores)}')\n",
    "\n",
    "    return LinearRegression().fit(X, y)\n",
    "\n",
    "df2 = df.set_index('PassengerId')\n",
    "\n",
    "fit_mlr(df2, label='Survived')\n",
    "model = fit_crossvalidate_mlr(df2, 5, 'Survived', True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70d9c1ae698f9e11524533c08f608ce409219722385f62d36cf17eae98d28817"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
